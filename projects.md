# ğŸ¯ Projects â€” Expanded Scopes, Deliverables & Rubrics

## Mini-Project 1 â€” AI-Generated BRD Draft

**Objective:** Turn a messy problem statement into a crisp, AI-assisted Business Requirements Document.

**Inputs:** Stakeholder notes, 1â€“2 user personas, 3â€“5 business goals.
**Core Tasks:** Problem framing â†’ scope & out-of-scope â†’ requirements (business/functional/non-functional) â†’ assumptions/risks â†’ acceptance criteria.
**Deliverables:**

* `Projects/MiniProject1_BRD_Draft/BRD.md` (â‰¤6 pages)
* `stakeholders.md` (RACI + contact cadence)
* `requirements_traceability.csv` (Req â†” AC â†” Test placeholder)
  **Acceptance (0â€“100):** Clarity 30 â€¢ Traceability 25 â€¢ Risk/assumptions 20 â€¢ Testability 15 â€¢ Executive tone 10
  **Timebox:** 4â€“6 hours
  **Starter prompt:** â€œYou are a principal BA. Draft a BRD from these notes. Separate business/functional/non-functional reqs; each must be testable.â€

---

## Mini-Project 2 â€” Process Flow + Refined BRD

**Objective:** Visualize the target process and harden requirements.

**Inputs:** Mini-Project 1 BRD; event/exception cases.
**Core Tasks:** As-Is/To-Be flows, swimlanes, exceptions, data handoffs; refine BRD and ACs.
**Deliverables:**

* `process_to_be.mmd` (Mermaid) + PNG export
* `exceptions_catalog.md` (top 10 edge cases)
* Updated `BRD.md` (versioned diffs)
  **Acceptance (0â€“100):** Correctness 30 â€¢ Exceptions 25 â€¢ Readability 20 â€¢ Alignment w/ BRD 15 â€¢ Versioning hygiene 10
  **Timebox:** 6â€“8 hours
  **Starter prompt:** â€œCreate a To-Be swimlane in Mermaid from this BRD. Call out 5 exception paths and data handoffs.â€

---

## Mini-Project 3 â€” Refined BRD + Testing Plan

**Objective:** Prove testability with a tight UAT pack and traceability.

**Inputs:** Refined BRD, flows, ACs.
**Core Tasks:** UAT test plan, test cases, entry/exit criteria, defect triage flow, RTM.
**Deliverables:**

* `uat_test_plan.md` (scope, roles, E2E scenarios)
* `test_cases.xlsx` (scenario â†’ steps â†’ expected â†’ priority)
* `rtm.csv` (Req â†’ AC â†’ TestCase â†’ Owner)
  **Acceptance (0â€“100):** Coverage 35 â€¢ Clarity 25 â€¢ RTM integrity 25 â€¢ Triage workflow 15
  **Timebox:** 6â€“8 hours
  **Starter prompt:** â€œGenerate UAT scenarios from these ACs. Prioritize with MoSCoW; include negative tests and data setup.â€

---

## Capstone â€” AI BA Portfolio Pitch

**Objective:** Package your artifacts into a 7â€“10 minute board-ready narrative.

**Core Tasks:** Story arc, live or screenshot demo, quantified outcomes, risks/mitigations, next steps.
**Deliverables:**

* `slides/capstone_deck.pdf` (9â€“12 slides)
* `demo_script.md` (timestamps + links)
* `portfolio_index.md` (artifact map + outcomes)
  **Acceptance (0â€“100):** Narrative 20 â€¢ Artifact quality 30 â€¢ Executive clarity 20 â€¢ Governance 15 â€¢ Q\&A 15
  **Timebox:** 1â€“2 days (including rehearsal)
  **Starter prompt:** â€œTurn these artifacts into a 9-slide exec deck: decision-first, outcomes quantified, one risk slide.â€

---

## ğŸ” Optional Project Tracks (Pick 1â€“3 to stand out)

### A) Data-Viz Decision Pack (PowerBI/Tableau/R)

**Goal:** One page that answers â€œWhat changed? Why? What now?â€
**Deliverables:** KPI tiles, trend with deltas, funnel/pareto, variance waterfall + **3 action bullets** with owners/dates.
**Acceptance:** Insight/actionability over aesthetics (0â€“100): Insight 40 â€¢ Accuracy 30 â€¢ Storytelling 20 â€¢ Hygiene 10.
**Timebox:** 6â€“8 hours.

### B) API-First Requirements (OpenAPI + Postman)

**Goal:** Make requirements unambiguous via contracts.
**Deliverables:** `openapi.yaml`, Postman collection, sample payloads + error codes, contract tests.
**Acceptance:** Spec completeness 40 â€¢ Error handling 25 â€¢ Examples 20 â€¢ Collection usability 15.

### C) Agentic Automation (Zapier/Make/Power Automate)

**Goal:** Automate a daily digest or BRD change notifier with retries and alerts.
**Deliverables:** Flow export, error policy (idempotency, 3Ã— retry, DLQ), ops runbook.
**Acceptance:** Reliability 40 â€¢ Observability 25 â€¢ Security (no secrets in logs) 20 â€¢ Docs 15.

### D) Responsible AI Pack

**Goal:** Prove you can ship AI safely.
**Deliverables:** 1-page AI Use Policy, DPIA-lite, eval harness (10 prompts w/ expected), red-team log (8 attacks).
**Acceptance:** Policy clarity 30 â€¢ Risk coverage 30 â€¢ Evals/metrics 25 â€¢ Red-team insights 15.

### E) UAT Simulation w/ Stakeholders

**Goal:** Run a time-boxed UAT with two personas.
**Deliverables:** Schedule, scripts, sign-off sheet, defect log with severities/SLAs, summary.
**Acceptance:** Coverage 35 â€¢ Evidence 30 â€¢ Triage discipline 20 â€¢ Comms 15.

### F) Stakeholder Comms Pack

**Goal:** Decision-first communication at exec level.
**Deliverables:** One-pager (Problem/Options/Rec/Risks/Next 30/90), 10-Q FAQ, 5-slide mini-deck.
**Acceptance:** Executive clarity 40 â€¢ Concision 30 â€¢ Anticipatory FAQ 20 â€¢ Visual hygiene 10.

### G) ROI & Scenario Modeling (Finance)

**Goal:** Tie requirements to dollars.
**Deliverables:** Driver-based model (assumptions tab), 3 scenarios (base/low/high), sensitivity tornado, 1-page CFO brief.
**Acceptance:** Assumption rigor 35 â€¢ Scenario clarity 30 â€¢ Visuals 20 â€¢ CFO-friendly narrative 15.

---

## ğŸ§° Suggested Repo Layout (Projects)

```text
Projects/
â”œâ”€â”€ MiniProject1_BRD_Draft/
â”‚   â”œâ”€â”€ BRD.md
â”‚   â”œâ”€â”€ stakeholders.md
â”‚   â””â”€â”€ requirements_traceability.csv
â”œâ”€â”€ MiniProject2_ProcessFlow/
â”‚   â”œâ”€â”€ process_to_be.mmd
â”‚   â”œâ”€â”€ process_to_be.png
â”‚   â””â”€â”€ exceptions_catalog.md
â”œâ”€â”€ MiniProject3_Refined_BRD/
â”‚   â”œâ”€â”€ uat_test_plan.md
â”‚   â”œâ”€â”€ test_cases.xlsx
â”‚   â””â”€â”€ rtm.csv
â”œâ”€â”€ Capstone_AI_BA_Pitch/
â”‚   â”œâ”€â”€ slides/capstone_deck.pdf
â”‚   â”œâ”€â”€ demo_script.md
â”‚   â””â”€â”€ portfolio_index.md
â””â”€â”€ Optional_Tracks/
    â”œâ”€â”€ DataViz_DecisionPack/
    â”œâ”€â”€ API_First_OpenAPI/
    â”œâ”€â”€ Agentic_Automation/
    â”œâ”€â”€ Responsible_AI/
    â”œâ”€â”€ UAT_Simulation/
    â”œâ”€â”€ Stakeholder_Comms/
    â””â”€â”€ ROI_Scenarios/
```

---

## âœ… Portfolio Bar (What â€œGreatâ€ Looks Like)

* Traceability from **BRD â†’ Flow â†’ AC â†’ Test â†’ API** is demonstrably tight.
* Dashboards tell a **decision story** (insight, cause, action with owner/date).
* Automation has **retries, idempotency, and alerts**; runbook included.
* AI work shows **governance** (policy, DPIA-lite, evals, red-team).
* Exec materials are **decision-first** and succinct.
* Capstone is **rehearsed** and time-boxed with clean handoffs.

---

## ğŸ§ª Quick Rubric (Global, 0â€“100)

* Problem clarity & scoping â€” 15
* Requirements quality & testability â€” 20
* Visualization & narrative (insight/action) â€” 15
* Automation reliability & ops hygiene â€” 15
* Governance (policy, risk, evals) â€” 15
* Executive communication â€” 20
  **Pass bar:** â‰¥ 90; no category < 60.

---

Want me to auto-generate empty stubs and template files for each project folder too?
